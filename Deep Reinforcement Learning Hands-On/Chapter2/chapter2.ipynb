{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "chapter2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QeI3vTEW57A"
      },
      "source": [
        "# Agent anatomy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLrYz15MW57B",
        "outputId": "3407a658-0fca-4cae-fd6b-65c2670c3e60"
      },
      "source": [
        "import random\n",
        "\n",
        "class Environment:\n",
        "  def __init__(self):\n",
        "    self.steps_left = 10\n",
        "        \n",
        "  def get_observation(self):\n",
        "    return [0.0, 0.0, 0.0]\n",
        "    \n",
        "  def get_actions(self):\n",
        "    return [0, 1]\n",
        "    \n",
        "  def is_done(self):\n",
        "    return self.steps_left == 0\n",
        "    \n",
        "  def action(self, action):\n",
        "    if self.is_done():\n",
        "        raise Exception(\"Game is over\")\n",
        "    self.steps_left -= 1\n",
        "    return random.random()\n",
        "\n",
        "class Agent:\n",
        "  def __init__(self):\n",
        "    self.total_reward = 0.0\n",
        "        \n",
        "  def step(self, env):\n",
        "    current_obs = env.get_observation()\n",
        "    actions = env.get_actions()\n",
        "    reward = env.action(random.choice(actions))\n",
        "    self.total_reward += reward\n",
        "\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "while not env.is_done():\n",
        "  agent.step(env)\n",
        "\n",
        "print(\"Total reward: %.4f\" % agent.total_reward)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total reward: 4.3641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u03LUP08hE9Z"
      },
      "source": [
        "# CartPole random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyREYq3AhLj3",
        "outputId": "34eb2490-2858-4536-a5ef-7700f7bd6681",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make('CartPole-v0')\n",
        "total_reward = 0.0\n",
        "total_steps = 0\n",
        "obs = env.reset()\n",
        "\n",
        "while True:\n",
        "  action = env.action_space.sample()\n",
        "  obs, reward, done, _ = env.step(action)\n",
        "  total_reward += reward\n",
        "  total_steps += 1\n",
        "  if done:\n",
        "    break\n",
        "\n",
        "print(\"Episode done in %d steps, total reward %.2f\" % (total_steps, total_reward))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode done in 31 steps, total reward 31.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmAG5LUZl_ho"
      },
      "source": [
        "# Random action wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z5MUA2ZkoFY"
      },
      "source": [
        "class RandomActionWrapper(gym.ActionWrapper):\n",
        "  def __init__(self, env, epsilon=0.1):\n",
        "    super(RandomActionWrapper, self).__init__(env)\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def action(self, action):\n",
        "    if random.random() < self.epsilon:\n",
        "      print(\"Random!\")\n",
        "      return self.env.action_space.sample()\n",
        "    return action\n",
        "\n",
        "env = RandomActionWrapper(gym.make(\"CartPole-v0\"))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSBsnwrJmqDK",
        "outputId": "c9c19a46-3e2d-44a5-b9c4-6500a4fa7c4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "obs = env.reset()\n",
        "total_reward = 0.0\n",
        "\n",
        "while True:\n",
        "  obs, reward, done, _ = env.step(0)\n",
        "  total_reward += reward\n",
        "  if done:\n",
        "    break;\n",
        "\n",
        "print(\"Reward got: %.2f\" % total_reward)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random!\n",
            "Random!\n",
            "Reward got: 12.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52g-MlLHn0pd"
      },
      "source": [
        "# CartPole random monitor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPNeCmF1nK1U"
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")\n",
        "env = gym.wrappers.Monitor(env, \"recording\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47QW0OXeowOw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}